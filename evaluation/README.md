# üî¨ Sistema de Avalia√ß√£o de Agentes de IA

Framework completo e **reutiliz√°vel** para avaliar sistemas multi-agentes usando m√©tricas avan√ßadas com RAGAs.

## üìã O que este sistema avalia

### üéØ **Roteamento de Agentes**
- Verifica se as mensagens s√£o direcionadas para o agente correto
- Mede accuracy de roteamento por agente
- Identifica casos de roteamento incorreto

### üß† **Uso de Contexto**
- Avalia se agentes consideram mensagens anteriores
- Testa continuidade conversacional  
- Verifica refer√™ncias a intera√ß√µes passadas

### üìä **Qualidade das Respostas (RAGAs)**
- **Answer Relevancy**: Relev√¢ncia da resposta
- **Answer Correctness**: Corre√ß√£o factual
- **Answer Similarity**: Similaridade sem√¢ntica
- **Faithfulness**: Fidelidade ao contexto

### ‚ö° **Performance**
- Tempo de resposta por teste
- Distribui√ß√£o de lat√™ncia
- Identifica√ß√£o de gargalos

## üöÄ Como usar

### **1. Instala√ß√£o**

```bash
# Na pasta evaluation/
pip install -r requirements.txt
```

### **2. Configurar ambiente**

Crie arquivo `.env` na raiz do projeto:
```
OPENAI_API_KEY=sua_chave_openai_aqui
```

### **3. Executar avalia√ß√£o**

```bash
# M√©todo simples
python run_evaluation.py

# M√©todo avan√ßado  
python agent_evaluator.py
```

### **4. Ver resultados**

Os resultados s√£o salvos em `results/` com:
- üìä **Gr√°ficos est√°ticos** (PNG)
- üåê **Dashboard interativo** (HTML)
- üìà **Relat√≥rio completo** (JSON)
- üìã **Dados tabulares** (CSV)

## üìÅ Estrutura do projeto

```
evaluation/
‚îú‚îÄ‚îÄ agent_evaluator.py      # Motor principal de avalia√ß√£o
‚îú‚îÄ‚îÄ run_evaluation.py       # Script de execu√ß√£o r√°pida  
‚îú‚îÄ‚îÄ test_cases.json         # Casos de teste
‚îú‚îÄ‚îÄ config.json            # Configura√ß√µes
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îî‚îÄ‚îÄ results/              # Resultados gerados
    ‚îú‚îÄ‚îÄ evaluation_report_YYYYMMDD_HHMMSS.json
    ‚îú‚îÄ‚îÄ evaluation_results_YYYYMMDD_HHMMSS.csv
    ‚îú‚îÄ‚îÄ evaluation_charts_YYYYMMDD_HHMMSS.png
    ‚îî‚îÄ‚îÄ interactive_dashboard_YYYYMMDD_HHMMSS.html
```

## üß™ Casos de teste inclu√≠dos

### **Roteamento b√°sico**
- ‚úÖ Finan√ßas ‚Üí FinanceAgent
- ‚úÖ Tecnologia ‚Üí TechSupportAgent  
- ‚úÖ Vendas ‚Üí SalesAgent
- ‚úÖ RH ‚Üí HRAgent
- ‚úÖ Fora de escopo ‚Üí TriageAgent

### **Contexto conversacional**
- üí¨ Perguntas dependentes de mensagens anteriores
- üîÑ Fluxos de conversa multi-turno
- üìù Refer√™ncias a intera√ß√µes passadas

### **Casos extremos**
- üåê Dom√≠nios mistos (finance + tech)
- üìè Mensagens muito longas
- ‚ùì Perguntas amb√≠guas

## üìä M√©tricas de sucesso

### **Thresholds esperados:**
- üéØ **Routing Accuracy**: > 85%
- üß† **Context Usage**: > 75%  
- ‚ö° **Response Time**: < 5000ms
- üìà **RAGAs Score**: > 0.7

### **Interpreta√ß√£o RAGAs:**
- **0.8 - 1.0**: üü¢ Excelente
- **0.6 - 0.8**: üü° Bom
- **0.4 - 0.6**: üü† Regular  
- **< 0.4**: üî¥ Ruim

## üîß Personaliza√ß√£o para outros projetos

### **1. Modificar casos de teste**

Edite `test_cases.json`:
```json
{
  "test_cases": [
    {
      "id": "seu_teste_01",
      "message": "Sua mensagem de teste",
      "expected_agent": "SeuAgentEsperado",
      "expected_response_type": "tipo_resposta",
      "context_dependent": false,
      "ground_truth": "Resposta esperada para compara√ß√£o RAGAs"
    }
  ]
}
```

### **2. Configurar API endpoints**

Modifique `config.json`:
```json
{
  "api_config": {
    "base_url": "http://seu-servidor:porta",
    "endpoints": {
      "send_message": "/seu/endpoint/chat",
      "clear_history": "/seu/endpoint/limpar"
    }
  }
}
```

### **3. Adaptar mapeamento de agentes**

No `config.json`:
```json
{
  "agent_mapping": {
    "seu_dominio": ["SeuAgent", "palavra_chave1", "palavra_chave2"]
  }
}
```

## üìà Relat√≥rios gerados

### **JSON Completo**
```json
{
  "summary": {
    "total_tests": 18,
    "routing_accuracy": 0.944,
    "context_usage_rate": 0.833,
    "avg_response_time_ms": 1250.5
  },
  "ragas_metrics": {
    "answer_relevancy": 0.857,
    "answer_correctness": 0.789,
    "answer_similarity": 0.823,
    "faithfulness": 0.901
  },
  "agent_performance": {
    "routing_accuracy_by_agent": {
      "FinanceAgent": 0.900,
      "TechSupportAgent": 1.000,
      "SalesAgent": 0.950
    }
  }
}
```

### **Dashboard Interativo**
- üìä Gr√°ficos interativos com Plotly
- üîç Drill-down por agente
- üìà Tend√™ncias temporais
- üéØ An√°lise de performance

## üö® Troubleshooting

### **Erro: "RAGAs n√£o encontrado"**
```bash
pip install ragas>=0.1.0
```

### **Erro: "API n√£o conecta"**
1. Verifique se API est√° rodando
2. Confirme URL no config.json
3. Teste: `curl http://localhost:8000/status`

### **Erro: "OpenAI API Key inv√°lida"**
1. Verifique `.env` com chave v√°lida
2. Confirme formato: `sk-...`
3. Teste no OpenAI Playground

### **Resultados inconsistentes**
1. Limpe hist√≥rico entre execu√ß√µes
2. Verifique casos de teste duplicados
3. Aguarde alguns segundos entre testes

## üîÑ Execu√ß√£o cont√≠nua

### **Para monitoramento cont√≠nuo:**

```bash
# Script para execu√ß√£o agendada
#!/bin/bash
cd /caminho/para/evaluation
python run_evaluation.py
# Enviar relat√≥rio por email/slack
```

### **Para CI/CD:**

```yaml
# .github/workflows/agent-evaluation.yml
name: Agent Evaluation
on: [push, schedule]
jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - run: |
          cd evaluation
          pip install -r requirements.txt
          python run_evaluation.py
```

## üéØ Pr√≥ximos passos

Ap√≥s executar a avalia√ß√£o:

1. **Analise o relat√≥rio** gerado
2. **Identifique pontos fracos** no roteamento
3. **Compare m√©tricas** entre vers√µes
4. **Otimize prompts** dos agentes
5. **Execute novamente** para medir melhoria

---

**üí° Este framework √© totalmente reutiliz√°vel para qualquer sistema multi-agentes!**

Basta adaptar os casos de teste e configura√ß√µes para seu projeto espec√≠fico.
